%\documentclass[11pt,final,a4paper,leqno]{article}
\documentclass[11pt,final,a4paper]{article}
\usepackage[ngerman,english]{babel}
%\usepackage{ucs}
\usepackage[T1]{fontenc}
\usepackage{color}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{listings}
\usepackage{fancyvrb}
\usepackage{textcomp}
\usepackage{setspace}
%\usepackage{MnSymbol}
\usepackage{amsmath} % flush eqations to the left
%\usepackage{amssymb}
%\usepackage{mathtools}

%\input{haskellstyle}

%\lstnewenvironment{haskell}{%
%  \lstset{}% 
%  \csname lst@SetFirstLabel\endcsname
%}
%{%
%  \csname lst@SaveFirstLabel\endcsname
%}

%\lstset {
%  basicstyle=\small\ttfamily,
%  flexiblecolumns = false,
%  basewidth = {0.5em, 0.45em},
%  literate = {+}{{$+$}}1 {/}{{$/$}}1 {*}{{$*$}}1 {=}{{$=$}}1
%             {>}{{$>$}}1 {<}{{$<$}}1 {\\}{{$\lambda$}}1
%             {\\\\}{{\char`\\\char`\\}}1
%             {->}{{$\rightarrow$}}2 {>=}{{$\geq$}}2 {<-}{{$\leftarrow$}}2
%             {<=}{{$\leq$}}2 {=>}{{$\Rightarrow$}}2 
%             {\ .}{{$\circ$}}2 {\ .\ }{{$\circ$}}2
%             {>>}{{>>}}2 {>>=}{{>>=}}2
%             {|}{{$\mid$}}1
%             {<<<}{{$\lll$}}2 {>>>}{{$\ggg$}}2 {-<}{{$\leftY$}}1
%}
%\lstset{                                % Definition der Sprache, f?r lstListings 
%        language=Haskell,               % Name der Sprache
%        breaklines=true,                % Sollen zu lange Zeilen umgebrochen werden?
%        captionpos=b,                   % Wo soll die Beschriftung stehen? (b - bottom, t - top)
%        tabsize=2,                      % Wie viele Zeichen springt ein Tab?
%        basicstyle=\small,              % Welche Schriftgr??e soll verwendet werden?
%        morekeywords={},    		% W?rter die als Schl?sselw?rter fett gedruckt werden sollen
%        deletekeywords={} 		% W?rter die nicht als Schl?sselw?rter fett gedruckt werden sollen
%}

\lstnewenvironment{haskell}[1][]{
  \lstset{
    fancyvrb=true, columns=flexible, language=haskell,
    captionpos=b,
    basicstyle=\ttfamily\small\setstretch{1},
    commentstyle=\color{ggray}\slshape,
    upquote=true,
    emph={True,False}, emphstyle=\color{green},
    literate=*{...}{{\textcolor{ggray}{...}}}{3}%
             {\{}{{\textcolor{blue}{\{}}}{1}%
             {\}}{{\textcolor{blue}{\}}}}{1}%
             {->}{{$\rightarrow$ }}{2},
    stringstyle=\color{red}, showstringspaces=false,
    keywordstyle=\color{blue},#1
}}{}

\newcommand{\hs}[1]{%
  \lstinline[
    fancyvrb=true, columns=flexible, language=haskell,
    captionpos=b,
    basicstyle=\ttfamily\setstretch{1},
    commentstyle=\color{ggray}\slshape,
    upquote=true,
    emph={True,False}, emphstyle=\color{green},
    literate=*{...}{{\textcolor{ggray}{...}}}{3}%
             {\{}{{\textcolor{blue}{\{}}}{1}%
             {\}}{{\textcolor{blue}{\}}}}{1}%
             {->}{{$\rightarrow$ }}{2},
    stringstyle=\color{red}, showstringspaces=false,
    keywordstyle=\color{blue}]!#1!%
}
\definecolor{gray}{gray}{0.5}
\definecolor{ggray}{gray}{0.7}
\definecolor{green}{rgb}{0,0.5,0}


\title{Hardware Design with Functional Datastructures: Functions, Arrows, Tupels, Vectors, and Inspection} 

\definecolor{textgray}{gray}{0.25}
\definecolor{backgray}{gray}{0.95}

\newcommand{\grafik}[4][0.9]{%        % Bild einfügen, [Skalierung], {Dateiname ohne Endung}, {Beschriftung}, {label zum Referenzieren}
    \begin{figure}[ht]%               % before: htbp 
        \begin{center}
            \includegraphics[width=#1\columnwidth]{Images/#2}
            \caption{\label{#4} #3}
            
        \end{center}
    \end{figure}
}

\newcommand{\xfig}[4][0.9] {%      %xfig figure einfügen, [Skalierung], {Dateiname ohne Endung}, {Beschriftung}, {label}
    \begin{figure}[ht]
        \begin{center}
            \graphicspath{{./}{Images/}}
            \scalebox{#1}{%
                \input{Images/#2}
            }
            \caption{\label{#4} #3}
        \end{center}
    \end{figure}
}

\newcommand{\reFLect}{\textit{re\kern-0.07em F\kern-0.07emL\kern-0.29em\raisebox{0.56ex}{ect}}}

\newcommand{\boxit}[1]{\mbox{{\it #1}}}

%\newcommand{\hs}[1]{\mbox{\lstinline[basicstyle=\color{textgray}]!#1!}}
%\newcommand{\hsLine}[1]{$$\mbox{\tt{#1}}$$}


\begin{document}

\section{Introduction}

%Tobias: Die Einleitung wuerde gut in Deine Doktorarbeit passen und die wuerde ich da auch reinkopieren.
%        Wahrscheinlich -- abhaengig von der Konferenz wo wir einreichen wollen -- bruachen wir aber eine 
%        andere. --> Ich wuerd das eher zum Schluss genau ausformulieren.

\label{introduction}
With the rise of rapid prototyping and development methodologies for FPGAs in hardware design, hardware has started to get softer. 
Going further, it feels natural to take even more concepts from the domain of software engineering. This can be seen in
hardware description languages like VHDL or Verilog. Both have taken their syntax from common languages like C and ADA which are
imperative progamming languages. For many reasons, functional programming languages could the problem of hardware modeling even
more naturally: 
\begin{itemize}
  \item \emph{Referential transparency}: While imperative languages force the programmer to prescribe the control flow a
  functional programming is stateless, i.e. the programmer does not prescribe control flow. Therefore concurrency isn't something
  that needs to be simulated (like it's done in System-C) but fits natural in the language and the developed code.
  \item \emph{Composition}: Functional programs are mainly (functional) compositions. Analogously, a hardware design mainly is a
  composition of a set of simpler gates. 
  \item \emph{Type systems}: Functional languages like Haskell come with an expressive type system which helps to detect errors early and
    also helps the developer to a cleaner design.
  \item \emph{Higher-order functions}: Typical functional design techniques like higher order functions can be used to abstract common
    circuit structures, so that the developer's task is to instantiate them in order to get circuits. 
  \item \emph{Lazy evaluation}: With the help of lazy evaluating languages it is easy to express infinite data structures, which also maps
    natural to stream processing hardware specifications. 
\end{itemize}

This properties lead to some interesting development possibilities which are common in the functional programming world, but are rather
unusual if not impossible in languages like VHDL\@. With the use of higher order functions developers are able to transform circuits just to
their needed behavior. The clean detachment of the languages semantics from the circuits specification is the key that leads to an extreme
flexible design. Last but not least the clear expressiveness of functional languages makes it easy to \emph{1:} reason, \emph{2:} realize
and \emph{3:} analyze functional programs. % TODO do i need to cite sheeran here? -- Yes :-)

In fact, these are old news, functional programming pioneers pointed to the use of functional languages as perfect hardware design languages
long before. \cite{sheeran:perfect_match} %O'Donnell and all the others\ldots

From the authors point of view it is not only natural to describe hardware with the help of functional programming languages, 
but also it is the logical step. 
% Das ist denke ich zu subjektiv formuliert und wuerde ich daher eher einfach rausnehmen.

\section{Hardware Modeling in the Functional Programming Paradigm: Recent Approaches}
\label{recent_approaches}
As stated in the introduction, modeling hardware in functional languages is old news, there have been various approaches in the past. The
beginning dates back into the early 80s where Mary Sheeran came up with a functional HDL muFP\cite{sheeran:muFP}. In the same decade John
O'Donnell presented his functional HDL HDRE\cite{hydra:old,donnell}. These two HDL's gave birth to numerous later approaches that are base
more or less on them. 

One of Sheeran's students, Coen Claessen, came later up with a monadic solution called Lava\cite{claessen:hardware}. Ingo Sanders et al
introduced an approach, ForSyDe \cite{forsyde:phd,forsyde:ieee} that is based on meta programming techniques. Lava, ForSyDe and also Mydra %TODO : Hydra reference in literature
represent HDL's embedded into the functional programming language Haskell; MyHDL \cite{myhdl} is embedded in the functional flavored
interpreting language Python. There is HML\cite{hml}, a simple HDL which is embedded inside ML, another functional programming language. 

Than there are functional languages that are exclusively designed to describe hardware, like the language SAFL (=Statically Allocated
Functional Language)\cite{sharp,sharp:flash,sharp:codesign}. This one compiles direct into a netlists; it does not support dynamic allocated
storage like heaps or stacks since these kind of software features do not map well on silicone. 

Another candidate for the functional metaprogramming languages section is the language \reFLect \cite{reflect}. This one is developed at
Intel and tailored for hardware design and theorem proving. 

There are good reasons why metaprogramming (also called \emph{reflexivity}) is beneficial for the use as HDLs. Metaprogramming allows a
program to have a representation of itself, usually by providing data structure of the abstract syntax tree. With this tool at hand the
developer is able to \emph{compute} parts of their program rather than \emph{write}them. This leads to a direct and natural implementation
of program transformations. Haskell also allows to metaprogramming through a library called ``Template Haskell''\cite{haskell:template}. 

With cryptol\cite{cryptol:programming} another class of functional HDLs enters the scene. While all the other HDL's are general purpose,
cryptol is designed to model cryptographic hardware. A sublanguage of cryptol is designed by Galois, explicit to generate FPGA
implementations \cite{cryptol:fpga}. Cryptol has lately been adopted by an American agency and isn't public developed anymore.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Why Arrows?}
In this section we give a short introduction to the concept of arrows; we briefly compare them to monads which are better known in the
functional community. We the show why to use arrows model hardware. 

\subsection{What is an Arrow?}

The concept of a function is a pillar in functional programming and can't be compared to functions in imperative/procedural programming
languages. In languages of the latter kind, functions are seen as structuring elements that stuff imperative expressions together while also
make them available by a specific identifier, the function name. In purely functional languages, a function is a mathematical
funtion: The output of a function is fully determined by its input, i.\,e. a function is free of side-effects. 

So the question is, how to express side effects (state changes like IO) with the use of side-effect free functions. This dilemma can be solved
by making the state changes deterministic, which is done via a \emph{world parameter}. A function that takes such a world parameter than
is able to react on the world's state, can apply changes and could deliver it in the return value. With this trick it is possible to express
IO-, random or any side effecting function in a functional language. This world parameter could also be used to gain the control flow back,
such that a specific chain of functions, is executed in the given order. Because it is tedious to keep track of this world parameter, it is
captured inside a specific data structure, which then is called a Monad. With monads the developer is able to determine a specific control
flow. On one side this is better than no control flow but on the other side it is to specific to design parallel computations which are
usual found in hardware designs. 

At this point, the concept of arrows comes to play, which represents the generalization of monads \cite{Hughes98generalisingmonads}. While
the monad is the abstract interface to the control flow of a function, the more general arrow states an abstract interface to all features
of a function.

\subsection{Arrows in the Hardware Design Process}
The similarity of functions on the one hand and hardware blocks on the other hand is well known and demonstrated in the functional
programming literature for the last decades \cite{sheeran:perfect_match,donnell}. While these similarities between those two are impressive,
there are also differences that need to be handled. Every approach that models hardware via functional functions has to face the fact, that
functional functions are extreme powerful. Functional concepts like higher-order functions, curried functions, etc\. doesn't map to silicon at
all. 

We conclude that Haskell functions correlate to logic gates on the one hand and offer some incompatible features on the other hand. To
describe hardware components with functional languages, only a very specific subset of the features of a Haskell function can be mapped to
circuit design. Every functional solution tackles theses differences by some means or other. This gives rise to such a manifold solution
space as described in section~\ref{recent_approaches}. The approaches cope this problem via monads, avoidance of functional features or via
meta programming techniques. 

As monads give the developer a handle to control the execution flow of functional programs, arrows offer a handle not only to the control
flow of functional functions, but to many more features of functions. In example, it is possible to specify the execution order but it is
not mandatory to do so. Such a behavior where parallelism is implicit, naturally fits to the behavior of silicone where parallelism also is
implicit. Another example is the ad-hoc creation of functions, so called lambdas in Haskell. The arrow interface provides a function that
can ``lift'' any other function into an arrow and so this mechanism can be used to specify lambda expressions inside arrows. As said
earlier, arrows provide handles to different building blocks of functional functions. Ad hoc creation of hardware blocks is something that
isn't possible and therefor is not used to model hardware. %% TODO : Kommt der unterschied zur vermeidung functionaler features hier raus?

\begin{itemize}
  \item Arrows compromise deep and shallow embedding, and seem to pick the benfits of both.a
  \item Arrows resemble premonoidal effect categories and\ldots   are a common way for category theorists to model the
  semantics of programming languages in a maximal generic way. In this view, arrows are executable maximum generic
  semantic specifications. With this genericity, one can hope to be able to do many things with such a specification:
  Execution, Synthesis, Proofing, (dependend on the concrete instance of the arrow)
  \item Interface (i.\,e. \hs{***}, \hs{&&&}, \hs{>>>}) is natural for combining hardware blocks
\end{itemize}


Haskells type of a function that takes input of type $b$ to output of type $c$ is denoted as $b \rightarrow c$, with the $(\rightarrow)$
being a \emph{higher-order-type}. This higher order type takes two type arguments (namely $b$ and $c$) and yields a type as result (namely
the function type $(\rightarrow)\ b\ c$). $(\rightarrow)$ is just the prefix notation of the infix type operator $\rightarrow$. To take
control over the features of a function, the function type operator $\rightarrow$ needs to be replaced by something more general; a higher
order type variable $a$. This leads to the prefix written type:

\begin{center}
\begin{minipage}{.2\textwidth}
\begin{haskell}
a b c
\end{haskell}
\end{minipage} \end{center}

Because this is to general to be of any use, Haskells \emph{type classes} are used to specify the properties of that type variable $a$. This
type class is called \hs{Arrow}. 

\begin{haskell}
class Arrow a b c where 
  arr   :: (b -> c) -> a b c
  (>>>)  :: a b c    -> a c d   -> a b d
  (***) :: a b c    -> a b' c' -> a (b, b') (c, c')
  (&&&) :: a b c    -> a b  c' -> a  b      (c, c')
\end{haskell}

In this type class a function \hs{arr} to lift ordinary functions into an arrow, the bind operator \hs{(>>>)}, as well as the combination
operator \hs{(***)} are defined. \hs{(&&&)} is just a special case of \hs{(***)}. 


With the bind operator \hs{(>>>)} two arrows are combined into a new one and the specific arrows are executed in sequence from left to
right. This corresponds directly to sequencing circuit, where one gate computes first with it's outputs solder to the next gate. 
 
To model parallel computation the \hs{(***)}-operator is used. It take two different data flows ($b$ and $b'$), passes them into the first
and the second arrow. The results ($c$ and $c'$) are than combined and yielded as overall result. The \hs{(&&&)}-operator takes only one
input and provides it to both inner arrows.

\xfig[.6]{ArrowStarStarStar}{Schematic representation of ***}{figure:ststst}
\xfig[.6]{ArrowAndAndAnd}{Schematic representation of (\&\&\&)}{figure:ananan}


Interestingly, this structure is at the same time the implementation of a lately developed concept in category theory, called Freyd~categories 
which are essentially premonoidal effect categories\cite{Heunen06arrows, Hughes98generalisingmonads,PatersonRA}. The term "`Freyd
Category"' essentially marks a functor with another category in its domain. The important part is, that it specifies a category of
computations and therefore a mathematical definition for category theorists to model the semantics of programming languages. To have such a
direct connection to category theory helps to underly our approach with mathematical proof in the future. This also shows that the arrow
approach is a generic semantic for describing hardware systems. Also such a generic system not only can be used to model the hardware, but
also to synthesis, code generation, simulation or property proofing. 


And there are more possibilities while using this approach. Another interesting arrow typeclass is the \hs{ArrowChoice} class. With a choice
arrow a model of different execution paths, depending on input parameters, could be expressed. This behavior is translated into Haskell's
\hs{Either} type and so it the result of type \hs{Either}. 

\begin{haskell}[]
class ArrowChoice a where
  (+++) :: a b c -> a b' c' -> Either (b b') (c c')
  (|||) :: a b c -> a b' c  -> Either (b b')  c 
\end{haskell}

Here again are two incarnations of that choice-operator. There is the \hs{(|||)}-operator, which combines two arrows with different input
types to an arrow of the same output type. Than there is the more abstract version, the \hs{(+++)}-operator which not only accepts two
different input types, but also returns two different output types.  

\xfig[.8]{ArrowPlPlPl}{Schematic representation of \hs{+++}}{figure:plplpl}
\xfig[.8]{ArrowPiPiPi}{Schematic representation of \hs{|||}}{figure:pipipi}


Relevant for hardware development is also the \hs{ArrowLoop} typeclass that is able to express recursive circuits where the output value
is fed back into the arrow..
\begin{haskell}[]
class ArrowLoop a where
  loop :: a (b, d) (c, d) -> a b c
\end{haskell}

This one is essential for hardware development because there are considerable few circuits which go without recursion. 

\xfig[.8]{ArrowLp}{Schematic representation of loop}{figure:loop}


% TODO 

\begin{itemize}
  \item arrows sind getupelt
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{First Approach: Classical Arrows}
Within this section, we present a basic cycle redundancy check implementation with the design method of arrows. The example shows a typical
way to express hardware with the functional method and also the flexibility of a functional approach is demonstrated. This is done by
implementing multiple CRC's with differing polynomials. How to generate netlists out of the functional data structure is shown later on.
After that, the problems with classical arrows are highlighted and solutions are discussed.


\subsection{Implementation}
The calculation of a specific CRC to some input data is based upon a mathematical method called a polynomial division. The reminder of that
devision is the CRC Checksum. The original data padded by the CRC results in 0 if that devision is done again. 


First of all there are operators, that are essential to work with this classical arrows, because of their tuple like inner structure. This
means, that each circuit is processing only a few inputs to output. The inputs therefore need to be reordered previous to each function
call. One function, that is responsible for this tupel'ing process is \hs{mvRight}. This function takes an argument of the structure
\((x,(y,z))\) to a different structure \((y,(x,z))\). 

\begin{haskell}
mvRight :: (Arrow a) => Grid a (my, (b, rst)) (b, (my, rst))
mvRight 
  =   aDistr
  >>> first aSnd
\end{haskell} 

The first arrow that is invoked here is \hs{aDistr} which is the pendant of the distribution law. \hs{aDistr} takes something of structure
\(x, (y, z)\) into something of structure \((x, y), (x, z))\), it distributes the first element over the second one. That arrow is combined
with another one, namely \hs{first aSnd}. In fact, this really is an arrow \hs{aSnd} with a scoop-operator \hs{first} such that \hs{aSnd}
works only on the first element of the tuple. The resulting arrow takes a structure \(((x_1,x_2), (y_1,y_2))\) to a resulting structure
\((x_2, (y_1, y_2))\). In the end the \hs{mvRight} arrow moves the first element of the tuple one step to the right. Of curse this function
assumes a structure where always the first element of a tuple is a value, the second is another tuple such like: \((v_1, (v_2, (v_3, (v_4,
v_5, (\dots)))))\)



Another common task over these list like tuple structure is to apply one arrow to the front and than concentrate with the remaining arrows
on the remaining structure. For this purpose the operator \hs{>:>} helps to clarify the 
\begin{haskell}
  aA >:> aB = aA >>> (second aB)
\end{haskell} 

The operator \hs{>:>} is based on the \hs{>>>} operator with a minor difference. The first supplied arrow is executed over the whole input
data tuple, while the second arrow is only applied to the second part of that tuple. Such an operator comes handy while list like tuple
structures are used and are processed from the left to the right. This is exactly the case for the polynomial division. 



While working with tuple lists, it is often convenient to just reorder the parenthesis around the data so that the selector functions like
\hs{first} result in just the right behavior. Two arrows are mentioned here that exploit the associativity of arrows, namely \hs{a\_aBC2ABc}
and \hs{a\_ABc2aBC}. The somewhat cryptographic names only mirror the changing parenthesis, upper case letters show the two positions that
are enclosed by the brackets, the lower case letter is the isolated position. 
\begin{align*}
  \text{a\_aBC2ABc} &: (a, (b, c)) \rightarrow ((a, b), c) \\
  \text{a\_ABc2aBC} &: ((a, b), c) \rightarrow (a, (b, c))
\end{align*}



The \hs{toInner} function makes use of the previously defined operators. There are several \hs{toInner} functions, that only differ in the
amount of steps the value is pushed into the list like tuple.
\begin{haskell}
toInner5
  =   mvRight
  >:> mvRight
  >:> mvRight
  >:> mvRight
  >:> aFlip
\end{haskell} 



With \hs{crc\_checksum\_8} a higher order function is defined that abstracts the general principle behind an 8 bit CRC sum function.  
\begin{haskell}
crc_checksum_8 crc_polynom polySkip padding start rest
  =   (padding &&& aId)
  >>> toInner8

  >>> (start &&& rest)
  >>> first (crc_polynom)

  >>> step
  >>> step
  >>> step
  >>> step
  >>> step
  >>> step

  >>> aFlip
  >>> polySkip
  >>> crc_polynom

  where step =   a_aBC2ABc
             >>> first 
                 (   aFlip
                 >>> polySkip
                 >>> crc_polynom
                 )   
\end{haskell} 

Before starting to calculate the CRC, the input data need to be properly aligned. Therefore the padding bits, which are all $0$ for the
calculation of the CRC, are ``moved'' to right end of the tuple list which for any 8 bit wide CRC algorithm is done via the \hs{toInner8}.
\[((p_0, p_1), (b_0, (b_1, (b_2, (b_3, b_4))))) \rightarrow (b_0, (b_1, (b_2, (b_3, (b_4, (p_0, p_1))))))\]


Afterwards the arrow actually abstracts the steps to be done to calculate a 8 bit CRC sum. The combined action \hs{(start &&& rest)} splits
the input data stream into the just enough bits that fill the Galois type shift register (the \hs{start} part) and into the remaining bits
(the \hs{rest} part). Keep in mind that the \hs{&&&} operator first duplicates its input and passes each arrow one copy. The starting bits
are then fed into the shift register via the \hs{first (crc\_polynom)} expression. Step by step all the bits are consumed, $1$ bit for every
\hs{step}. The last step is executed without the need of the \hs{first} selector, because there are no reminding bits left and for that
reason the arrow ends with the \hs{aFlip >>> polySkip >>> crc\_polynom} expression. 


\subsection{Simple Example}
There are lots of CRC-Codes out there and every one is equipped with a polynomial that especially fits the needs of its domain. In this
examples the simple CRC-Codes for USB and CCIT are shown. Their polynomials are:
\begin{align*}
  \text{USB} &: x^5 + x^2 + 1 \\
  \text{CCIT}&: x^4 + x   + 1 
\end{align*}

These polynomials describe at which positions the input bit is \hs{xor}'ed with that bit that has traveled all the way through the shift
register. For the USB CRC $\text{bit}_0$ and $\text{bit}_2$ are \hs{xor}'ed with $\text{bit}_5$, for the CCIT CRC the $\text{bit}_0$ and
$\text{bit}_1$ are \hs{xor}'ed with $\text{bit}_4$. 

\begin{figure}
  \centering
  \graphicspath{{./}{Images/}}
  \mbox{%
    \subfigure[USB CRC]{\scalebox{0.5}{\input{./Images/CRC-USB}}} \quad \quad \quad \quad
    \subfigure[CCIT CRC]{\scalebox{0.5}{\input{./Images/CRC-CCIT}}}
  }
\end{figure}



The question is, what \hs{polySkip}, \hs{crc\_polynom}, \hs{padding}, \hs{start} and \hs{rest} values need to be chosen. To summarize this
for the CCIT CRC, the highest exponent is $4$. This means, that:
\begin{itemize}
  \item the \hs{polySkip} needs to be \hs{toInner4}
  \item there are $4$ \hs{padding} bits \hs{aConst (False, (False, (False, False)))} 
  \item the split between \hs{start} and \hs{rest} is after bit $4$
\end{itemize}

So the resulting definition of the CCIT CRC sum is:
\begin{haskell}
crc_checksum_ccit_8 
  :: Arrow a => Grid a 
    (Bool, (Bool, (Bool, (Bool, (Bool, (Bool, (Bool, Bool))))))) 
    (Bool, (Bool, (Bool, Bool)))
crc_checksum_ccit_8
  = crc_checksum_8   
      crc_polynom_ccit
      toInner4
      (aConst (False, (False, (False, False))))
      (second.second.second.second $ aFst)
      (aSnd >>> aSnd >>> aSnd >>> aSnd >>> aSnd)
\end{haskell} 

\subsection{Building Netlists}
The data type of the previous CRC function denotes a \hs{Graph} arrow. This is because the arrow generates a graph which in fact holds all
the information that are needed to generate netlists out of it. Basically a graph could be seen as a different form of a Netlist. In Haskell
a graph is modeled by two lists, one for the nodes and one for the edges.


Every hardware component is identified by an ID that is represented by an integer value. This holds also for the in and output pins of
hardware components. The Pins also have IDs that are identified by an integer value.
\begin{haskell}
type CompID = Int
type PinID  = Int
type Pins   = [PinID]
\end{haskell}


An edge represents a wire between two pins on different components and is identified by the tuple of \hs{CompID} and \hs{PinID} which is
called an \hs{AnchorPoint}. There are also two different anchor points, one that goes into a component called \hs{SinkAnchor} as well as one
that comes from a component, the \hs{SourceAnchor}. 

\begin{haskell}
type AnchorPoint  = (Maybe CompID, PinID)
type SinkAnchor   = AnchorPoint
type SourceAnchor = AnchorPoint
\end{haskell}

Note that the \hs{Maybe} constructor is used here, because there can be edges / wires from and to nowhere. These represent the edges of a
component which are not yet connected to the outside world. This by the way maps also to the real world, where it is normal, that
components which are not yet placed have pins from and to nowhere. 


An edge is a wire, is a connection between two components or to be more precise, it is a connection between two anchor points. 
\begin{haskell}
data Edge 
  = MkEdge { sourceInfo :: SourceAnchor
           , sinkInfo   :: SinkAnchor }
\end{haskell}
The record notation is used, to obtain accessor functions (\hs{sourceInfo} and \hs{sinkInfo}) within one step. 

 
Last but not least the actual graph is defined. It holds the information about the node which is similar to the component. The name is later
used in the VHDL generation to identify the entities. Every node holds a list of sub nodes that represent from what this node is build and
helps to build up complex structures from basic simple building blocks. It also holds a list of the connected edges, as well as the list of
input- and output pins. Accessor function are also gained through the use of the record notation.
\begin{haskell}
data StructGraph
  = MkSG { name    :: String
         , compID  :: CompID
         , nodes   :: [StructGraph]
         , edges   :: [Edge]
         , sinks   :: Pins
         , sources :: Pins }   
\end{haskell}

\subsection{Drawbacks}

This approach basically comes with two problems. 

As the CRC example shows up, all the input data to these hardware components must fit into simple tuples. This is easy to handle if the
components only come with one or two pins and certainly which is the case for simple logic gates. But at the latest if the modeled
hardware component uses more than two pins, different data structures are needed. Up to a certain degree one can simulate a
list-like structure with tuples (as it is done in the above CRC examples). But the simulation comes at a cost. 
A big part of the code is needed for restructuring tuples; the CRC example only is an $8$-bit gate and even more restructuring
will be necessary for modeling real world logic gates. This process becomes more tedious, confusing and error prone, if something
like 32 bit hardware components should be modeled. 

The tedious tuple code could at least be superficially avoided by the use of Patterson's  proc-notation for
arrows\cite{PatersonNewNotation}.  The proc-notation abstracts the tuples code, and the hardware can be described more ``visually'' in the
source code. But the proc-notation is just syntactic sugar and underneath there are still tuples in use. 
The following code shows how the CCIT CRC polynomial can be modeled with the proc-notation: 
\begin{haskell}
crc_polynom_ccit 
 = proc (b4, (b3, (b2, (b1, b0)))) -> do
     b4' <- aId  -< (b3)
     b3' <- aId  -< (b2)
     b2' <- aXor -< (b4, b1)
     b1' <- aXor -< (b4, b0)
     returnA     -< (b4', (b3', (b2', b1')))
\end{haskell} 


But there is also a problem with that notation which comes from the auto generated arrow code. Patterson's notation makes a lot use of the
\hs{arr} function of an arrow. But because it is possible to ``lift'' any function passed to \hs{arr} into an arrow, it is impossible to
keep track of the types of that functions. Nevertheless at least the type of the passed function is needed to generate a nice \hs{Grid}
arrow, that can be transformed into Netlists later. 

% TODO Type for \hs{arr}-Argument (e.g. \hs{\x y z -> (.\ \.\ \.\ )}) is not available for later calculations (to generate the netlists, usw.)

Both the type of an arrow \hs{a b c} itself and the type of the arrows combinators do not perfectly natural for hardware design.
The type \hs{a b c} is too general for a logic gate: type of the data going into a logic gate should always be the same as
the type of the values going out of this logic gate. Secondly, a set of wires actually is not a tuple and, for instance, the tuple
\hs{(a,(b,(c,d)))} represents the same set of wires as the tuple \hs{(a,((b,c),d))} and the number of possible (different with
respect to syntax and type) representations of a set of wires exponentially explodes with a growing number wires we are trying to
model. 

\section{Arrows on Vectors}



\begin{haskell}
class VArrow (~~>) where
  arr     :: ((Vec n b)->(Vec m b)) -> (Vec n b)~~>(Vec m b)
  firsts  :: (Vec n b)~~>(Vec m b) -> (Vec (n:+k) b)~~>(Vec (m:+k) b)
  seconds :: (Vec n b)~~>(Vec m b) -> (Vec (k:+n) b)~~>(Vec (k:+m) b)
  (>>|) :: (Vec n b)~~>(Vec m b) -> (Vec m b)~~>(Vec k b) -> (Vec n b)~~>(Vec k b)
  (**|) :: (Vec n b)~~>(Vec m b) -> (Vec k b)~~>(Vec j b) -> (Vec (n:+k) b)~~>(Vec (m:+j) b)
  (&&|) :: (Vec n b)~~>(Vec m b) -> (Vec n b)~~>(Vec k b) -> (Vec n b)~~>(Vec (m:+k) b)
\end{haskell}


\subsection{Horn-Clause-Solution}

\subsection{Type-Family-Solutions}

-  :+: and :-:
- \ldots

Conclusion: That is dependent typing and Haskell is not (yet) a dependently typed function programming laguage. And all
in all it seems that the Vec-Type together with the Arrows-Instances is too much dependent typing for Haskell

\subsection{Using a dependently types language}

\section{Copeing with \hs{arr}-Problem}

\subsection{ForSyDe: Using the AST of the arr argument}

In order to transform a usual Haskell function into an hardware block, ForSyDe stores the AST of that function which is
used later to synthesis VHDL.

\subsection{Show-Type-Class (or Typeable)}

\subsection{Generalized Arrows -- avoiding arr}


\bibliographystyle{plain}
\bibliography{Bibliography}
\end{document}
